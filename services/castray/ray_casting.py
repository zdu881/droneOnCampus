import ray
import asyncio
import socket
import threading
import time
import json
import uuid
import os
import platform
from pathlib import Path
from typing import Dict, List, Optional, Set, Any
from .models import CastMessage, CastType, MessageType, CastResponse, NodeStatus
from .file_transfer import FileTransferManager, FileTransferMessage, FileTransferProtocol
import logging

# å¯¼å…¥é›†ç¾¤å‘ç°æ¨¡å—ï¼ˆä½¿ç”¨ç›¸å¯¹å¯¼å…¥ä»¥ä¾¿æœ¬åŒ…åŒ–ï¼‰
try:
    from .ray_cluster_discovery import discover_and_connect_external_clusters, cluster_connector
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæä¾›ç©ºçš„æ›¿ä»£å‡½æ•°
    def discover_and_connect_external_clusters():
        return {'discovered_clusters': [], 'external_nodes': {}, 'success': False}
    
    class DummyConnector:
        def get_external_nodes(self):
            return {}
        def is_connected_to_external_cluster(self):
            return False
    
    cluster_connector = DummyConnector()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

_MAX_CONNECTION_HISTORY = 30

def _classify_ray_error(err: Exception) -> str:
    """æ ¹æ®å¼‚å¸¸ä¿¡æ¯ç²—ç•¥åˆ†ç±»é”™è¯¯ç±»å‹ï¼Œä¾¿äºæ—¥å¿—è¿‡æ»¤ä¸è·¨é›†ç¾¤æ’éšœã€‚
    åˆ†ç±»æ ‡ç­¾ï¼šnetwork | runtime_env | timeout | auth | interrupt | unknown
    """
    msg = str(err) or ''
    lower = msg.lower()
    if 'connection refused' in lower or 'cannot connect' in lower or 'timeout' in lower or 'timed out' in lower or 'unreachable' in lower:
        return 'network'
    if 'runtime_env' in lower or 'working_dir' in lower or 'packaging' in lower or 'hash_directory' in lower:
        return 'runtime_env'
    if 'auth' in lower or 'permission' in lower or 'denied' in lower:
        return 'auth'
    if isinstance(err, KeyboardInterrupt):
        return 'interrupt'
    if 'cancelled' in lower:
        return 'timeout'
    return 'unknown'

def connect_to_ray_cluster(ray_address: Optional[str] = None, namespace: str = "castray", allow_local_fallback: bool = True):
    """è¿æ¥åˆ°å·²æœ‰çš„Rayé›†ç¾¤æˆ–å¯åŠ¨æ–°é›†ç¾¤ã€‚
    è®°å½•è€—æ—¶ä¸é”™è¯¯åˆ†ç±»ï¼Œå†™å…¥å…¨å±€ cluster è¿æ¥å†å²ï¼ˆè‹¥ cluster å·²åˆ›å»ºï¼‰ã€‚
    """
    start_ts = time.time()
    attempt_meta = {
        'ray_address': ray_address,
        'namespace': namespace,
        'allow_local_fallback': allow_local_fallback,
        'phase': 'start',
        'start_time': start_ts,
        'duration': None,
        'success': False,
        'error': None,
        'error_class': None,
    }
    try:
        # å¦‚æœRayå·²ç»åˆå§‹åŒ–ï¼Œå…ˆå…³é—­
        if ray.is_initialized():
            ray.shutdown()
        
        # è·å–Rayé›†ç¾¤åœ°å€
        if ray_address is None:
            ray_address = os.environ.get('RAY_ADDRESS', 'local')
        
        # é…ç½®è¿è¡Œæ—¶ç¯å¢ƒï¼š
        # - å¯¹äºå¤–éƒ¨é›†ç¾¤è¿æ¥ï¼Œä¸è®¾ç½® working_dirï¼Œé¿å…å¤§ç›®å½•æ‰“åŒ…/ä¸Šä¼ å¯¼è‡´è¶…æ—¶
        # - æœ¬åœ°/auto æ¨¡å¼å¯ä»¥ä¿ç•™ working_dirï¼Œä¾¿äºåœ¨åŒæœºç¯å¢ƒä¸‹åŠ è½½æœ¬åœ°ä»£ç 
        runtime_env: Dict[str, Any] = {}
        if platform.system() == "Linux":
            if ray_address in ['auto', 'local', None]:
                runtime_env = {
                    "working_dir": os.getcwd(),
                    "env_vars": {
                        "PYTHONPATH": os.getcwd(),
                        "RAY_DISABLE_IMPORT_WARNING": "1"
                    }
                }
            else:
                # å¤–éƒ¨åœ°å€ï¼šä»…ä¼ å…¥å¿…è¦ envï¼Œé¿å…è§¦å‘ working_dir æ‰“åŒ…
                runtime_env = {
                    "env_vars": {
                        "RAY_DISABLE_IMPORT_WARNING": "1"
                    }
                }
        
        # ç®€åŒ–åˆå§‹åŒ–é€»è¾‘ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å¼é¿å…è¿æ¥é—®é¢˜
        if ray_address in ['auto', 'local', None]:
            # å¯åŠ¨æœ¬åœ°é›†ç¾¤
            logger.info("å¯åŠ¨æœ¬åœ°Rayé›†ç¾¤...")
            cpu_count = os.cpu_count() or 2
            num_cpus = max(1, cpu_count // 2)  # ä½¿ç”¨ä¸€åŠCPUæ ¸å¿ƒ
            
            ray.init(
                namespace=namespace, 
                runtime_env=runtime_env,
                ignore_reinit_error=True,
                dashboard_host='127.0.0.1',  # æ”¹ä¸ºæœ¬åœ°åœ°å€
                dashboard_port=8265,
                object_store_memory=100*1024*1024,  # 100MB
                num_cpus=num_cpus,
                _temp_dir=os.path.join(os.getcwd(), "ray_temp")  # æŒ‡å®šä¸´æ—¶ç›®å½•
            )
            logger.info("æˆåŠŸå¯åŠ¨æœ¬åœ°Rayé›†ç¾¤")
            logger.info(f"Ray Dashboard: http://127.0.0.1:8265")
            logger.info(f"Rayé›†ç¾¤èµ„æº: {ray.cluster_resources()}")
            attempt_meta.update({'success': True, 'phase': 'local_start'})
            return True
        else:
            # è¿æ¥åˆ°æŒ‡å®šåœ°å€ - ä¸æä¾›ç¡¬ä»¶èµ„æºå‚æ•°
            logger.info(f"å°è¯•è¿æ¥åˆ°æŒ‡å®šRayé›†ç¾¤: {ray_address}")
            # æ³¨æ„ï¼šruntime_env ä¸åŒ…å« working_dirï¼Œé¿å…å¯¹å¤§ä»“åº“è¿›è¡Œæ‰“åŒ…
            ray.init(address=ray_address, namespace=namespace, runtime_env=runtime_env)
            logger.info(f"æˆåŠŸè¿æ¥åˆ°Rayé›†ç¾¤: {ray_address}")
            logger.info(f"Rayé›†ç¾¤èµ„æº: {ray.cluster_resources()}")
            attempt_meta.update({'success': True, 'phase': 'external_connect'})
            return True
        
    except Exception as e:
        logger.error(f"Rayé›†ç¾¤åˆå§‹åŒ–å¤±è´¥: {e}")
        attempt_meta.update({'error': str(e), 'error_class': _classify_ray_error(e)})
        # æœ€åçš„åå¤‡æ–¹æ¡ˆï¼šä»…åœ¨å…è®¸æ—¶å°è¯•æœ€ç®€å•çš„æœ¬åœ°åˆå§‹åŒ–
        if not allow_local_fallback:
            logger.info("å·²ç¦ç”¨æœ¬åœ°å›é€€åˆå§‹åŒ–ï¼ˆallow_local_fallback=Falseï¼‰")
            attempt_meta['phase'] = 'external_failed_no_fallback'
            attempt_meta['success'] = False
            attempt_meta['duration'] = time.time() - start_ts
            try:
                from .ray_casting import cluster as _cluster_ref  # circular safe: already in module
                if hasattr(_cluster_ref, 'connection_history'):
                    _cluster_ref.connection_history.append(attempt_meta)
                    if len(_cluster_ref.connection_history) > _MAX_CONNECTION_HISTORY:
                        _cluster_ref.connection_history.pop(0)
            except Exception:
                pass
            return False
        try:
            logger.info("å°è¯•æœ€ç®€å•çš„Rayæœ¬åœ°åˆå§‹åŒ–...")
            if ray.is_initialized():
                ray.shutdown()
            ray.init(ignore_reinit_error=True, log_to_driver=False)
            logger.info("ä½¿ç”¨ç®€åŒ–æ¨¡å¼æˆåŠŸå¯åŠ¨Ray")
            attempt_meta.update({'success': True, 'phase': 'fallback_minimal'})
            return True
        except Exception as fallback_e:
            logger.error(f"æœ€ç®€åŒ–Rayåˆå§‹åŒ–ä¹Ÿå¤±è´¥: {fallback_e}")
            attempt_meta.update({'error': f"fallback:{fallback_e}", 'error_class': _classify_ray_error(fallback_e), 'phase': 'fallback_failed'})
            return False
    finally:
        attempt_meta['duration'] = time.time() - start_ts
        # è¿½åŠ ç»“æ„åŒ–æ—¥å¿—ï¼ˆINFO çº§åˆ«ä¾¿äºæ”¶é›†ï¼‰
        try:
            logger.info(f"connect_attempt meta={json.dumps(attempt_meta, ensure_ascii=False)}")
        except Exception:
            logger.info(f"connect_attempt summary success={attempt_meta['success']} phase={attempt_meta['phase']} duration={attempt_meta['duration']:.3f}s class={attempt_meta.get('error_class')}")
        # å†™å…¥å…¨å±€ cluster å†å²ï¼ˆè‹¥å­˜åœ¨ï¼‰
        try:
            from .ray_casting import cluster as _cluster_ref  # already loaded
            if hasattr(_cluster_ref, 'connection_history'):
                _cluster_ref.connection_history.append(attempt_meta)
                if len(_cluster_ref.connection_history) > _MAX_CONNECTION_HISTORY:
                    _cluster_ref.connection_history.pop(0)
        except Exception:
            pass

@ray.remote
class CastingNode:
    """Rayè¿œç¨‹ç±»ï¼Œå¤„ç†å•ä¸ªèŠ‚ç‚¹çš„æ¶ˆæ¯ä¼ è¾“å’Œæ–‡ä»¶ä¼ è¾“"""
    
    def __init__(self, node_id: str, port: int = 0):
        self.node_id = node_id
        self.port = port
        self.is_running = False
        self.socket = None
        self.message_handlers = {}
        self.received_messages = []
        self.sent_messages = []
        
        # æ–‡ä»¶ä¼ è¾“ç®¡ç†å™¨
        self.file_transfer_manager = FileTransferManager(f"downloads/{node_id}")
        self.file_msg_factory = FileTransferMessage()
        
        # è‡ªåŠ¨ä¼ è¾“ä»»åŠ¡é˜Ÿåˆ—
        self.auto_transfer_queue = []
        self.auto_transfer_enabled = True
        
    async def start(self):
        """å¯åŠ¨èŠ‚ç‚¹"""
        try:
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            if self.port == 0:
                self.socket.bind(('localhost', 0))
                self.port = self.socket.getsockname()[1]
            else:
                self.socket.bind(('localhost', self.port))
            
            self.socket.settimeout(0.1)
            self.is_running = True
            logger.info(f"èŠ‚ç‚¹ {self.node_id} å¯åŠ¨åœ¨ç«¯å£ {self.port}")
            return True
        except Exception as e:
            logger.error(f"èŠ‚ç‚¹ {self.node_id} å¯åŠ¨å¤±è´¥: {e}")
            return False

    async def stop(self):
        """åœæ­¢èŠ‚ç‚¹"""
        self.is_running = False
        if self.socket:
            self.socket.close()
        logger.info(f"èŠ‚ç‚¹ {self.node_id} å·²åœæ­¢")

    async def send_unicast(self, message: dict, target_ip: str, target_port: int):
        """å‘é€å•æ’­æ¶ˆæ¯"""
        try:
            if not self.socket:
                return {"success": False, "error": "Socket not initialized"}
            
            message_data = json.dumps(message).encode('utf-8')
            self.socket.sendto(message_data, (target_ip, target_port))
            
            self.sent_messages.append({
                "type": "unicast",
                "target": f"{target_ip}:{target_port}",
                "message": message,
                "timestamp": time.time()
            })
            
            return {"success": True, "target": f"{target_ip}:{target_port}"}
        except Exception as e:
            logger.error(f"å•æ’­å‘é€å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def send_multicast(self, message: dict, group_ip: str, group_port: int):
        """å‘é€ç»„æ’­æ¶ˆæ¯"""
        try:
            multicast_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            multicast_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            
            # è®¾ç½®TTL
            multicast_socket.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)
            
            message_data = json.dumps(message).encode('utf-8')
            multicast_socket.sendto(message_data, (group_ip, group_port))
            multicast_socket.close()
            
            self.sent_messages.append({
                "type": "multicast", 
                "group": f"{group_ip}:{group_port}",
                "message": message,
                "timestamp": time.time()
            })
            
            return {"success": True, "group": f"{group_ip}:{group_port}"}
        except Exception as e:
            logger.error(f"ç»„æ’­å‘é€å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def send_broadcast(self, message: dict, broadcast_port: int):
        """å‘é€å¹¿æ’­æ¶ˆæ¯"""
        try:
            broadcast_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            broadcast_socket.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
            
            message_data = json.dumps(message).encode('utf-8')
            broadcast_socket.sendto(message_data, ('<broadcast>', broadcast_port))
            broadcast_socket.close()
            
            self.sent_messages.append({
                "type": "broadcast",
                "port": broadcast_port,
                "message": message,
                "timestamp": time.time()
            })
            
            return {"success": True, "broadcast_port": broadcast_port}
        except Exception as e:
            logger.error(f"å¹¿æ’­å‘é€å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def listen_for_messages(self):
        """ç›‘å¬æ¥æ”¶æ¶ˆæ¯"""
        while self.is_running:
            try:
                if self.socket:
                    data, addr = self.socket.recvfrom(65536)  # å¢å¤§ç¼“å†²åŒºä»¥æ”¯æŒæ–‡ä»¶å—
                    message = json.loads(data.decode('utf-8'))
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ä¼ è¾“æ¶ˆæ¯
                    if message.get("type", "").startswith("file_"):
                        await self.handle_file_message(message, addr)
                    else:
                        # æ™®é€šæ¶ˆæ¯
                        self.received_messages.append({
                            "from": f"{addr[0]}:{addr[1]}",
                            "message": message,
                            "timestamp": time.time()
                        })
                        
                        logger.info(f"èŠ‚ç‚¹ {self.node_id} æ”¶åˆ°æ¥è‡ª {addr} çš„æ¶ˆæ¯: {message}")
                    
            except socket.timeout:
                # å¤„ç†è‡ªåŠ¨ä¼ è¾“é˜Ÿåˆ—
                if self.auto_transfer_enabled:
                    await self.process_auto_transfers()
                continue
            except Exception as e:
                if self.is_running:
                    logger.error(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")
            
            await asyncio.sleep(0.01)

    async def initiate_file_transfer(self, file_path: str, recipients: List[str], 
                                   transfer_mode: str = "unicast"):
        """ä¸»åŠ¨å‘èµ·æ–‡ä»¶ä¼ è¾“"""
        try:
            if not os.path.exists(file_path):
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return {"success": False, "error": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            # åˆ›å»ºä¼ è¾“ä¼šè¯
            file_id = self.file_transfer_manager.initiate_file_transfer_sync(
                file_path, recipients, transfer_mode, self.node_id
            )
            
            # å‘é€ä¼ è¾“è¯·æ±‚
            request_msg = self.file_msg_factory.create_transfer_request(
                file_path, file_id, self.node_id, recipients, transfer_mode
            )
            
            # æ ¹æ®ä¼ è¾“æ¨¡å¼å‘é€è¯·æ±‚
            success_count = 0
            failed_recipients = []
            
            if transfer_mode == "unicast":
                # å•æ’­åˆ°æ¯ä¸ªæ¥æ”¶è€…
                for recipient in recipients:
                    success = await self._send_message_to_recipient(request_msg, recipient)
                    if success:
                        success_count += 1
                    else:
                        failed_recipients.append(recipient)
            elif transfer_mode == "broadcast":
                # å¹¿æ’­
                success = await self._send_broadcast_message(request_msg)
                if success:
                    success_count = len(recipients)
                else:
                    failed_recipients = recipients.copy()
            
            # å¦‚æœæœ‰å¤±è´¥çš„æ¥æ”¶è€…ï¼Œæ›´æ–°ç»Ÿè®¡
            if failed_recipients:
                self.file_transfer_manager.mark_transfer_failed(file_id, failed_recipients)
            
            logger.info(f"èŠ‚ç‚¹ {self.node_id} å‘èµ·æ–‡ä»¶ä¼ è¾“: {file_path} -> {recipients}, æˆåŠŸ: {success_count}, å¤±è´¥: {len(failed_recipients)}")
            
            return {
                "success": success_count > 0,
                "file_id": file_id,
                "recipients_notified": success_count,
                "failed_recipients": failed_recipients,
                "transfer_mode": transfer_mode,
                "message": f"æˆåŠŸé€šçŸ¥ {success_count}/{len(recipients)} ä¸ªæ¥æ”¶è€…"
            }
            
        except Exception as e:
            logger.error(f"å‘èµ·æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _send_message_to_recipient(self, message: dict, recipient_id: str):
        """å‘ç‰¹å®šæ¥æ”¶è€…å‘é€æ¶ˆæ¯"""
        try:
            # å°è¯•ä»Ray shared stateè·å–èŠ‚ç‚¹ç«¯å£æ˜ å°„
            try:
                # å°è¯•è·å–é›†ç¾¤ç®¡ç†å™¨çš„ç«¯å£æ˜ å°„
                cluster_manager = ray.get_actor("cluster_manager")
                node_ports = await cluster_manager.get_node_ports.remote()
                
                if recipient_id in node_ports:
                    recipient_port = node_ports[recipient_id]
                    message_data = json.dumps(message).encode('utf-8')
                    if self.socket:
                        self.socket.sendto(message_data, ('localhost', recipient_port))
                        logger.debug(f"å‘é€æ¶ˆæ¯åˆ° {recipient_id} (ç«¯å£: {recipient_port})")
                    return True
                else:
                    logger.warning(f"ç«¯å£æ˜ å°„ä¸­æœªæ‰¾åˆ°æ¥æ”¶è€…: {recipient_id}")
                    self.file_transfer_manager.transfer_stats["failed_transfers"] += 1
                    return False
                    
            except Exception as ray_error:
                logger.debug(f"æ— æ³•ä»Rayè·å–ç«¯å£æ˜ å°„: {ray_error}")
                # å›é€€ï¼šç›´æ¥å°è¯•ä»å…¶ä»–èŠ‚ç‚¹è·å–ç«¯å£
                if recipient_id in self.get_known_node_ports():
                    recipient_port = self.get_known_node_ports()[recipient_id]
                    message_data = json.dumps(message).encode('utf-8')
                    if self.socket:
                        self.socket.sendto(message_data, ('localhost', recipient_port))
                        logger.debug(f"å‘é€æ¶ˆæ¯åˆ° {recipient_id} (ç«¯å£: {recipient_port}) [å›é€€æ¨¡å¼]")
                    return True
                else:
                    logger.warning(f"æœªæ‰¾åˆ°æ¥æ”¶è€…åœ°å€: {recipient_id}")
                    self.file_transfer_manager.transfer_stats["failed_transfers"] += 1
                    return False
                    
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯åˆ° {recipient_id} å¤±è´¥: {e}")
            self.file_transfer_manager.transfer_stats["failed_transfers"] += 1
            return False

    def get_known_node_ports(self):
        """è·å–å·²çŸ¥çš„èŠ‚ç‚¹ç«¯å£ï¼ˆç¡¬ç¼–ç ä½œä¸ºå›é€€ï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªå›é€€æœºåˆ¶ï¼Œåœ¨æ— æ³•ä»Rayè·å–åŠ¨æ€ç«¯å£æ—¶ä½¿ç”¨
        return {}

    async def _send_broadcast_message(self, message: dict):
        """å‘é€å¹¿æ’­æ¶ˆæ¯"""
        try:
            broadcast_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            broadcast_socket.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
            
            message_data = json.dumps(message).encode('utf-8')
            broadcast_socket.sendto(message_data, ('<broadcast>', 9998))
            broadcast_socket.close()
            
            return True
        except Exception as e:
            logger.error(f"å¹¿æ’­æ¶ˆæ¯å¤±è´¥: {e}")
            return False

    async def handle_file_message(self, message: dict, sender_addr):
        """å¤„ç†æ–‡ä»¶ä¼ è¾“ç›¸å…³æ¶ˆæ¯"""
        try:
            msg_type = message.get("type", "")
            
            if msg_type == "file_transfer_request":
                # å¤„ç†æ–‡ä»¶ä¼ è¾“è¯·æ±‚
                response = self.file_transfer_manager.handle_transfer_request(message, auto_accept=True)
                await self._send_response_to_sender(response, sender_addr)
                
                logger.info(f"èŠ‚ç‚¹ {self.node_id} æ¥æ”¶æ–‡ä»¶ä¼ è¾“è¯·æ±‚: {message['file_info']['file_name']}")
                
            elif msg_type == "file_chunk":
                # å¤„ç†æ–‡ä»¶å—
                ack = self.file_transfer_manager.handle_chunk_message(message)
                await self._send_response_to_sender(ack, sender_addr)
                
                # æ£€æŸ¥æ˜¯å¦æ¥æ”¶å®Œæ‰€æœ‰å—
                file_id = message["file_id"]
                chunks = self.file_transfer_manager.received_chunks.get(file_id, [])
                expected_chunks = message["chunk"].get("total_chunks", 0)
                
                if len(chunks) == expected_chunks:
                    # å®Œæˆæ–‡ä»¶ä¼ è¾“
                    file_info = {"file_name": f"received_file_{file_id}", "file_hash": ""}
                    complete_response = self.file_transfer_manager.complete_file_transfer(file_id, file_info)
                    await self._send_response_to_sender(complete_response, sender_addr)
                    
            elif msg_type in ["file_transfer_accept", "file_transfer_reject"]:
                # å¤„ç†ä¼ è¾“å“åº”
                file_id = message["file_id"]
                transfer = self.file_transfer_manager.get_transfer_status(file_id)
                
                if transfer and msg_type == "file_transfer_accept":
                    # å¼€å§‹å‘é€æ–‡ä»¶å—
                    await self._start_sending_chunks(file_id, sender_addr)
                    
            elif msg_type == "file_chunk_ack":
                # å¤„ç†å—ç¡®è®¤
                logger.debug(f"æ”¶åˆ°å—ç¡®è®¤: {message}")
                
            elif msg_type == "file_transfer_complete":
                # å¤„ç†ä¼ è¾“å®Œæˆ
                logger.info(f"æ–‡ä»¶ä¼ è¾“å®Œæˆ: {message}")
                
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶æ¶ˆæ¯å¤±è´¥: {e}")
    
    async def _send_response_to_sender(self, response: dict, sender_addr):
        """å‘å‘é€è€…å‘é€å“åº”"""
        try:
            response_data = json.dumps(response).encode('utf-8')
            self.socket.sendto(response_data, sender_addr)
        except Exception as e:
            logger.error(f"å‘é€å“åº”å¤±è´¥: {e}")
    
    async def _start_sending_chunks(self, file_id: str, receiver_addr):
        """å¼€å§‹å‘é€æ–‡ä»¶å—"""
        try:
            transfer = self.file_transfer_manager.get_transfer_status(file_id)
            if not transfer:
                return
            
            chunks = transfer["chunks"]
            for chunk in chunks:
                chunk_msg = self.file_msg_factory.create_chunk_message(
                    file_id, chunk, self.node_id
                )
                
                chunk_data = json.dumps(chunk_msg).encode('utf-8')
                self.socket.sendto(chunk_data, receiver_addr)
                
                # æ·»åŠ å°å»¶è¿Ÿé¿å…ç½‘ç»œæ‹¥å¡
                await asyncio.sleep(0.01)
                
            logger.info(f"å®Œæˆå‘é€ {len(chunks)} ä¸ªæ–‡ä»¶å—")
            
        except Exception as e:
            logger.error(f"å‘é€æ–‡ä»¶å—å¤±è´¥: {e}")
    
    def schedule_auto_transfer(self, file_path: str, recipients: List[str], 
                             transfer_mode: str = "unicast", delay: float = 0):
        """å®‰æ’è‡ªåŠ¨æ–‡ä»¶ä¼ è¾“"""
        if self.auto_transfer_enabled:
            transfer_task = {
                "file_path": file_path,
                "recipients": recipients,
                "transfer_mode": transfer_mode,
                "schedule_time": time.time() + delay,
                "attempts": 0,
                "max_attempts": 3
            }
            self.auto_transfer_queue.append(transfer_task)
            logger.info(f"å®‰æ’è‡ªåŠ¨ä¼ è¾“: {file_path} -> {recipients} (å»¶è¿Ÿ: {delay}ç§’)")
    
    async def process_auto_transfers(self):
        """å¤„ç†è‡ªåŠ¨ä¼ è¾“é˜Ÿåˆ—"""
        current_time = time.time()
        completed_tasks = []
        
        for i, task in enumerate(self.auto_transfer_queue):
            if current_time >= task["schedule_time"]:
                try:
                    result = await self.initiate_file_transfer(
                        task["file_path"], 
                        task["recipients"], 
                        task["transfer_mode"]
                    )
                    
                    if result["success"]:
                        logger.info(f"è‡ªåŠ¨ä¼ è¾“æˆåŠŸ: {task['file_path']}")
                        completed_tasks.append(i)
                    else:
                        task["attempts"] += 1
                        if task["attempts"] >= task["max_attempts"]:
                            logger.error(f"è‡ªåŠ¨ä¼ è¾“å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {task['file_path']}")
                            completed_tasks.append(i)
                        else:
                            # é‡æ–°å®‰æ’
                            task["schedule_time"] = current_time + 10  # 10ç§’åé‡è¯•
                            
                except Exception as e:
                    logger.error(f"å¤„ç†è‡ªåŠ¨ä¼ è¾“ä»»åŠ¡å¤±è´¥: {e}")
                    completed_tasks.append(i)
        
        # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
        for i in reversed(completed_tasks):
            del self.auto_transfer_queue[i]
    
    def get_status(self):
        """è·å–èŠ‚ç‚¹çŠ¶æ€"""
        file_stats = self.file_transfer_manager.get_statistics()
        
        return {
            "node_id": self.node_id,
            "port": self.port,
            "is_running": self.is_running,
            "received_count": len(self.received_messages),
            "sent_count": len(self.sent_messages),
            "last_activity": max(
                [msg["timestamp"] for msg in self.received_messages] +
                [msg["timestamp"] for msg in self.sent_messages] + [0]
            ),
            "file_transfer_stats": file_stats,
            "active_transfers": len(self.file_transfer_manager.get_all_transfers()),
            "auto_transfer_queue": len(self.auto_transfer_queue),
            "auto_transfer_enabled": self.auto_transfer_enabled
        }
    
    def get_messages(self, count: int = 50):
        """è·å–æœ€è¿‘çš„æ¶ˆæ¯"""
        all_messages = []
        
        for msg in self.received_messages[-count:]:
            all_messages.append({
                "direction": "received",
                **msg
            })
        
        for msg in self.sent_messages[-count:]:
            all_messages.append({
                "direction": "sent", 
                **msg
            })
        
        return sorted(all_messages, key=lambda x: x["timestamp"], reverse=True)[:count]
    
    async def get_file_transfer_stats(self):
        """è·å–æ–‡ä»¶ä¼ è¾“ç»Ÿè®¡"""
        return self.file_transfer_manager.get_statistics()
    
    async def get_active_transfers_count(self):
        """è·å–æ´»è·ƒä¼ è¾“æ•°é‡"""
        return len(self.file_transfer_manager.get_all_transfers())
    
    async def enable_auto_transfer(self):
        """å¯ç”¨è‡ªåŠ¨ä¼ è¾“"""
        self.auto_transfer_enabled = True
        logger.info(f"èŠ‚ç‚¹ {self.node_id} è‡ªåŠ¨ä¼ è¾“å·²å¯ç”¨")
    
    async def disable_auto_transfer(self):
        """ç¦ç”¨è‡ªåŠ¨ä¼ è¾“"""
        self.auto_transfer_enabled = False
        logger.info(f"èŠ‚ç‚¹ {self.node_id} è‡ªåŠ¨ä¼ è¾“å·²ç¦ç”¨")
    
    def get_node_context(self):
        """è·å–å½“å‰Actorçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ‰€åœ¨çš„ç‰©ç†èŠ‚ç‚¹ID"""
        try:
            import ray
            runtime_context = ray.get_runtime_context()
            return {
                "actor_id": runtime_context.get_actor_id(),
                "physical_node_id": runtime_context.get_node_id(),
                "ip_address": runtime_context.get_node_ip_address(),
                "worker_id": runtime_context.get_worker_id(),
                "job_id": runtime_context.get_job_id()
            }
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {
                "actor_id": None,
                "physical_node_id": None,
                "ip_address": None,
                "worker_id": None,
                "job_id": None,
                "error": str(e)
            }


class CastingCluster:
    """æ¶ˆæ¯ä¼ è¾“é›†ç¾¤ç®¡ç†å™¨"""
    
    def __init__(self):
        self.nodes: Dict[str, Any] = {}  # Ray actor handles
        self.node_ports: Dict[str, int] = {}
        self.external_nodes: Dict[str, Dict] = {}  # å¤–éƒ¨èŠ‚ç‚¹ä¿¡æ¯
        self.is_initialized = False
        self.connection_history: List[Dict[str, Any]] = []  # æœ€è¿‘è¿æ¥å°è¯•çš„å…ƒæ•°æ®
    
    def get_connection_history(self) -> List[Dict[str, Any]]:
        """è¿”å›è¿æ¥å†å²ï¼ˆæµ…æ‹·è´ï¼‰ï¼Œä¾›å¤–éƒ¨è°ƒè¯•æˆ– API æš´éœ²ã€‚
        æ¯æ¡åŒ…å«: ray_address/phase/success/duration/error_class/errorã€‚
        """
        return list(self.connection_history)
        
    async def initialize_ray(self, ray_address: Optional[str] = None, namespace: str = "castray", allow_local_start: bool = True):
        """åˆå§‹åŒ–Rayé›†ç¾¤è¿æ¥"""
        try:
            # å¦‚æœæ˜¾å¼æä¾›äº† ray_addressï¼ˆé 'auto'/'local'/Noneï¼‰ï¼Œä¼˜å…ˆå°è¯•ç›´æ¥è¿æ¥è¯¥åœ°å€
            external_discovery_result = None
            if ray_address and ray_address not in ['auto', 'local', None]:
                logger.info(f"å°è¯•ç›´æ¥è¿æ¥åˆ°æŒ‡å®šçš„ Ray åœ°å€: {ray_address}")
                try:
                    direct_success = connect_to_ray_cluster(ray_address, namespace, allow_local_fallback=allow_local_start)
                    if direct_success:
                        self.is_initialized = True
                        logger.info(f"å·²è¿æ¥åˆ°æŒ‡å®š Ray åœ°å€: {ray_address}")
                        # å¦‚æœéœ€è¦ï¼Œå°è¯•å‘ç°ç°æœ‰çš„èŠ‚ç‚¹/Actors
                        try:
                            await self.discover_existing_nodes()
                        except Exception:
                            pass
                        return True
                    else:
                        logger.info(f"é€šè¿‡æŒ‡å®šåœ°å€ {ray_address} è¿æ¥å¤±è´¥ï¼Œç»§ç»­å°è¯•è‡ªåŠ¨å‘ç°æˆ–æœ¬åœ°å¯åŠ¨")
                except Exception as e:
                    logger.debug(f"ç›´æ¥è¿æ¥åˆ° {ray_address} æ—¶å‡ºé”™: {e}")

            # é¦–å…ˆå°è¯•å‘ç°å¤–éƒ¨Rayé›†ç¾¤
            external_discovery_result = None
            if ray_address in ['auto', None] or os.environ.get('DISCOVER_EXTERNAL_CLUSTERS', '').lower() == 'true':
                logger.info("ğŸ” å°è¯•å‘ç°å¤–éƒ¨Rayé›†ç¾¤...")
                external_discovery_result = discover_and_connect_external_clusters()
                
                if external_discovery_result.get('success'):
                    logger.info("âœ… å·²è¿æ¥åˆ°å¤–éƒ¨Rayé›†ç¾¤")
                    self.is_initialized = True
                    
                    # åŠ è½½å¤–éƒ¨èŠ‚ç‚¹
                    external_nodes = external_discovery_result.get('external_nodes', {})
                    self.external_nodes.update(external_nodes)
                    
                    logger.info(f"å‘ç° {len(external_nodes)} ä¸ªå¤–éƒ¨èŠ‚ç‚¹")
                    return True
                else:
                    logger.info(f"æœªå‘ç°å¤–éƒ¨é›†ç¾¤: {external_discovery_result.get('error', 'unknown')}")

                # å¦‚æœå‘ç°å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡ RAY_ADDRESSï¼ˆä¼˜å…ˆäºæœ¬åœ°è‡ªåŠ¨å¯åŠ¨ï¼‰
                env_ray_addr = os.environ.get('RAY_ADDRESS')
                if env_ray_addr:
                    logger.info(f"å¤–éƒ¨å‘ç°æœªæˆåŠŸï¼Œæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ RAY_ADDRESS={env_ray_addr}ï¼Œå°è¯•è¿æ¥è¯¥åœ°å€")
                    try:
                        success_env = connect_to_ray_cluster(env_ray_addr, namespace, allow_local_fallback=allow_local_start)
                        if success_env:
                            self.is_initialized = True
                            logger.info(f"å·²é€šè¿‡ RAY_ADDRESS={env_ray_addr} æˆåŠŸè¿æ¥åˆ° Ray é›†ç¾¤")
                            return True
                        else:
                            logger.warning(f"é€šè¿‡ RAY_ADDRESS={env_ray_addr} è¿æ¥å¤±è´¥")
                    except Exception as ee:
                        logger.debug(f"å°è¯•é€šè¿‡ RAY_ADDRESS è¿æ¥æ—¶å‡ºé”™: {ee}")

            # å¦‚æœæ²¡æœ‰å‘ç°å¤–éƒ¨é›†ç¾¤ï¼Œå†³å®šæ˜¯å¦å¯åŠ¨æœ¬åœ°Rayæˆ–ç›´æ¥è¿”å›å¤±è´¥
            if not allow_local_start:
                logger.info("allow_local_start=Falseï¼Œè·³è¿‡æœ¬åœ° Ray å¯åŠ¨ï¼›è‹¥æ²¡æœ‰å¤–éƒ¨é›†ç¾¤è¿æ¥ï¼Œåˆ™åˆå§‹åŒ–è§†ä¸ºå¤±è´¥")
                return False

            # å¦‚æœå…è®¸æœ¬åœ°å¯åŠ¨ï¼Œåˆ™ä½¿ç”¨åŸæœ‰çš„è¿æ¥é€»è¾‘
            success = connect_to_ray_cluster(ray_address, namespace, allow_local_fallback=allow_local_start)
            if success:
                self.is_initialized = True
                logger.info("Rayé›†ç¾¤åˆå§‹åŒ–æˆåŠŸ")

                # å¦‚æœè¿æ¥åˆ°å¤–éƒ¨é›†ç¾¤ï¼Œå°è¯•å‘ç°ç°æœ‰èŠ‚ç‚¹
                if ray_address and ray_address not in ['auto', 'local', None]:
                    await self.discover_existing_nodes()

                return True
            else:
                logger.error("Rayé›†ç¾¤åˆå§‹åŒ–å¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"Rayé›†ç¾¤åˆå§‹åŒ–å¤±è´¥: {e}")
            try:
                ray.init(ignore_reinit_error=True)
                self.is_initialized = True
                logger.info("Rayæœ¬åœ°æ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
                return True
            except Exception as e2:
                logger.error(f"Rayæœ¬åœ°æ¨¡å¼åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                return False

    async def discover_existing_nodes(self):
        """å‘ç°Rayé›†ç¾¤ä¸­çš„ç°æœ‰èŠ‚ç‚¹å’ŒActor"""
        try:
            logger.info("å‘ç°Rayé›†ç¾¤ä¸­çš„ç°æœ‰èŠ‚ç‚¹...")
            
            # è·å–é›†ç¾¤ä¿¡æ¯
            cluster_resources = ray.cluster_resources()
            available_resources = ray.available_resources()
            nodes = ray.nodes()
            
            logger.info(f"Rayé›†ç¾¤ä¿¡æ¯: {len(nodes)} ä¸ªèŠ‚ç‚¹, CPU: {cluster_resources.get('CPU', 0)}")
            
            # å°è¯•åˆ—å‡ºç°æœ‰çš„Named Actor
            try:
                # ç®€åŒ–çš„Actorå‘ç°é€»è¾‘
                import ray.util.state as state
                actors = state.list_actors()
                logger.info(f"å‘ç° {len(actors)} ä¸ªç°æœ‰Actor")
                
                for i, actor in enumerate(actors):
                    try:
                        # å®‰å…¨åœ°è®¿é—®actorå±æ€§
                        actor_dict = actor.__dict__ if hasattr(actor, '__dict__') else {}
                        state_val = getattr(actor, 'state', 'UNKNOWN')
                        name_val = getattr(actor, 'name', f'actor_{i}')
                        class_name_val = getattr(actor, 'class_name', 'unknown')
                        
                        if state_val == 'ALIVE' and name_val:
                            # æ£€æŸ¥æ˜¯å¦ä¸ºç›¸å…³çš„Actorç±»å‹
                            if any(keyword in str(class_name_val) for keyword in ['DemoNode', 'CastingNode', 'Node']):
                                logger.info(f"å‘ç°å¯èƒ½çš„ä¼ è¾“Actor: {name_val} ({class_name_val})")
                                
                                # ä¸ºå¤–éƒ¨Actoråˆ›å»ºä»£ç†æ¡ç›®
                                if name_val not in self.nodes:
                                    self.external_nodes[name_val] = {
                                        'actor_id': getattr(actor, 'actor_id', ''),
                                        'class_name': class_name_val,
                                        'state': state_val,
                                        'node_id': getattr(actor, 'node_id', ''),
                                        'is_external': True,
                                        'is_ray_node': False
                                    }
                                    logger.info(f"å·²è®°å½•å¤–éƒ¨Actor: {name_val}")
                    except Exception as actor_error:
                        logger.debug(f"å¤„ç†Actor {i} æ—¶å‡ºé”™: {actor_error}")
                        continue
                
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ—å‡ºç°æœ‰Actor: {e}")
            
            # æ ¹æ®Rayç‰©ç†èŠ‚ç‚¹åˆ›å»ºè™šæ‹Ÿä¼ è¾“èŠ‚ç‚¹
            node_count = 0
            for node in nodes:
                if node.get('Alive', False):
                    node_id = f"ray_node_{node_count + 1}"
                    # ä¸ºRayèŠ‚ç‚¹åˆ›å»ºè™šæ‹Ÿæ¡ç›®ï¼ˆä¸æ˜¯çœŸæ­£çš„CastingNode Actorï¼‰
                    self.external_nodes[node_id] = {
                        'ray_node_id': node.get('NodeID', ''),
                        'resources': node.get('Resources', {}),
                        'alive': node.get('Alive', False),
                        'is_ray_node': True,
                        'is_external': True
                    }
                    node_count += 1
                    logger.info(f"æ˜ å°„RayèŠ‚ç‚¹ä¸ºä¼ è¾“èŠ‚ç‚¹: {node_id}")
            
            logger.info(f"å‘ç° {len(self.external_nodes)} ä¸ªå¤–éƒ¨èŠ‚ç‚¹")
            
        except Exception as e:
            logger.error(f"å‘ç°ç°æœ‰èŠ‚ç‚¹å¤±è´¥: {e}")

    async def create_node(self, node_id: str, port: int = 0) -> bool:
        """åˆ›å»ºæ–°èŠ‚ç‚¹"""
        try:
            if not self.is_initialized:
                await self.initialize_ray()
            
            node_ref = CastingNode.remote(node_id, port)
            success = await node_ref.start.remote()
            
            if success:
                self.nodes[node_id] = node_ref
                if port == 0:
                    # è·å–å®é™…åˆ†é…çš„ç«¯å£
                    status = await node_ref.get_status.remote()
                    self.node_ports[node_id] = status["port"]
                else:
                    self.node_ports[node_id] = port
                    
                logger.info(f"èŠ‚ç‚¹ {node_id} åˆ›å»ºæˆåŠŸï¼Œç«¯å£: {self.node_ports[node_id]}")
                return True
            return False
        except Exception as e:
            logger.error(f"åˆ›å»ºèŠ‚ç‚¹ {node_id} å¤±è´¥: {e}")
            return False

    async def remove_node(self, node_id: str) -> bool:
        """ç§»é™¤èŠ‚ç‚¹"""
        try:
            if node_id in self.nodes:
                await self.nodes[node_id].stop.remote()
                del self.nodes[node_id]
                if node_id in self.node_ports:
                    del self.node_ports[node_id]
                logger.info(f"èŠ‚ç‚¹ {node_id} å·²ç§»é™¤")
                return True
            return False
        except Exception as e:
            logger.error(f"ç§»é™¤èŠ‚ç‚¹ {node_id} å¤±è´¥: {e}")
            return False

    async def get_node_ports(self) -> Dict[str, int]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹çš„ç«¯å£æ˜ å°„"""
        return self.node_ports.copy()

    async def send_message(self, cast_message: CastMessage) -> CastResponse:
        """å‘é€æ¶ˆæ¯"""
        start_time = time.time()
        results = []
        failed_recipients = []
        
        try:
            if cast_message.sender not in self.nodes:
                return CastResponse(
                    success=False,
                    message="å‘é€èŠ‚ç‚¹ä¸å­˜åœ¨",
                    recipients_count=0
                )
            
            sender_node = self.nodes[cast_message.sender]
            message_data = {
                "id": cast_message.id,
                "content": cast_message.content,
                "message_type": cast_message.message_type,
                "timestamp": cast_message.timestamp or time.time()
            }
            
            if cast_message.cast_type == CastType.UNICAST:
                # å•æ’­
                for recipient in cast_message.recipients:
                    if recipient in self.node_ports:
                        result = await sender_node.send_unicast.remote(
                            message_data, 'localhost', self.node_ports[recipient]
                        )
                        results.append(result)
                        if not result.get("success"):
                            failed_recipients.append(recipient)
                    else:
                        failed_recipients.append(recipient)
            
            elif cast_message.cast_type == CastType.MULTICAST:
                # ç»„æ’­
                group_ip = "224.1.1.1"  # ç¤ºä¾‹ç»„æ’­åœ°å€
                group_port = 9999
                result = await sender_node.send_multicast.remote(
                    message_data, group_ip, group_port
                )
                results.append(result)
                if not result.get("success"):
                    failed_recipients = cast_message.recipients
            
            elif cast_message.cast_type == CastType.BROADCAST:
                # å¹¿æ’­
                broadcast_port = 9998
                result = await sender_node.send_broadcast.remote(
                    message_data, broadcast_port
                )
                results.append(result)
                if not result.get("success"):
                    failed_recipients = list(self.nodes.keys())
            
            delivery_time = time.time() - start_time
            success_count = len([r for r in results if r.get("success")])
            
            return CastResponse(
                success=success_count > 0,
                message=f"æ¶ˆæ¯å‘é€å®Œæˆï¼ŒæˆåŠŸ: {success_count}, å¤±è´¥: {len(failed_recipients)}",
                recipients_count=success_count,
                failed_recipients=failed_recipients,
                delivery_time=delivery_time
            )
            
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            return CastResponse(
                success=False,
                message=f"å‘é€å¤±è´¥: {str(e)}",
                recipients_count=0,
                failed_recipients=cast_message.recipients
            )

    async def get_cluster_status(self) -> dict:
        """è·å–é›†ç¾¤çŠ¶æ€"""
        try:
            node_statuses = []
            
            # è·å–è‡ªå»ºèŠ‚ç‚¹çŠ¶æ€
            for node_id, node_ref in self.nodes.items():
                try:
                    status = await node_ref.get_status.remote()
                    node_statuses.append(status)
                except:
                    node_statuses.append({
                        "node_id": node_id,
                        "is_running": False,
                        "error": "æ— æ³•è·å–çŠ¶æ€"
                    })
            
            # æ·»åŠ å¤–éƒ¨èŠ‚ç‚¹çŠ¶æ€
            for node_id, node_info in self.external_nodes.items():
                if node_info.get('is_ray_node'):
                    # Rayç‰©ç†èŠ‚ç‚¹
                    node_statuses.append({
                        "node_id": node_id,
                        "is_running": node_info.get('alive', False),
                        "port": "N/A",
                        "node_type": "RayèŠ‚ç‚¹",
                        "resources": node_info.get('resources', {}),
                        "received_count": 0,
                        "sent_count": 0,
                        "auto_transfer_enabled": False,
                        "auto_transfer_queue": 0,
                        "file_transfer_stats": {
                            "successful_transfers": 0,
                            "failed_transfers": 0,
                            "bytes_transferred": 0
                        }
                    })
                else:
                    # å¤–éƒ¨ActorèŠ‚ç‚¹
                    node_statuses.append({
                        "node_id": node_id,
                        "is_running": node_info.get('state') == 'ALIVE',
                        "port": "N/A",
                        "node_type": "å¤–éƒ¨Actor",
                        "class_name": node_info.get('class_name', 'unknown'),
                        "received_count": 0,
                        "sent_count": 0,
                        "auto_transfer_enabled": False,
                        "auto_transfer_queue": 0,
                        "file_transfer_stats": {
                            "successful_transfers": 0,
                            "failed_transfers": 0,
                            "bytes_transferred": 0
                        }
                    })

            ray_status = {}
            try:
                if ray.is_initialized():
                    ray_status = {
                        "cluster_resources": ray.cluster_resources(),
                        "available_resources": ray.available_resources(),
                        "nodes": len(ray.nodes())
                    }
            except:
                ray_status = {"error": "æ— æ³•è·å–RayçŠ¶æ€"}

            total_nodes = len(self.nodes) + len(self.external_nodes)
            active_nodes = len([s for s in node_statuses if s.get("is_running", False)])

            return {
                "total_nodes": total_nodes,
                "active_nodes": active_nodes,
                "node_statuses": node_statuses,
                "ray_cluster": ray_status,
                "node_ports": self.node_ports
            }
        except Exception as e:
            logger.error(f"è·å–é›†ç¾¤çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}

    async def get_unified_nodes_status(self, dashboard_address: str = "10.30.2.11:8265"):
        """è·å–æ•´åˆäº†ç‰©ç†å’Œé€»è¾‘ä¿¡æ¯çš„èŠ‚ç‚¹çŠ¶æ€åˆ—è¡¨"""
        try:
            logger.info(f"get_unified_nodes_status called with dashboard_address={dashboard_address}")
            # 1. è·å–ç‰©ç†èŠ‚ç‚¹ä¿¡æ¯
            physical_nodes = get_physical_ray_nodes_status(dashboard_address)
            logger.info(f"å‘ç° {len(physical_nodes)} ä¸ªç‰©ç†RayèŠ‚ç‚¹")
            
            # 2. è·å–CastRayèŠ‚ç‚¹ä¿¡æ¯å¹¶è¿›è¡Œæ˜ å°„
            castray_node_tasks = []
            node_contexts = {}
            
            for node_id, actor in self.nodes.items():
                try:
                    # å¹¶è¡Œè·å–æ‰€æœ‰CastRayèŠ‚ç‚¹çš„çŠ¶æ€å’Œä¸Šä¸‹æ–‡
                    status_task = asyncio.create_task(actor.get_status.remote())
                    context_task = asyncio.create_task(actor.get_node_context.remote())
                    castray_node_tasks.append((node_id, status_task, context_task))
                except Exception as e:
                    logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥ for {node_id}: {e}")
            
            # 3. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
            for node_id, status_task, context_task in castray_node_tasks:
                try:
                    status = await status_task
                    context = await context_task
                    
                    # CastRay actor è¿”å›çš„ context ä¸­å¯èƒ½åŒ…å« runtime_context.get_node_id()ï¼ˆå®Œæ•´ node idï¼‰
                    # ä¹Ÿå¯èƒ½æ˜¯æŸäº›çŸ­ id æˆ–ç©ºå€¼ã€‚ä¸ºäº†æé«˜é²æ£’æ€§ï¼Œæˆ‘ä»¬å°è¯•å¤šç§åŒ¹é…ç­–ç•¥ï¼š
                    # 1) ç›´æ¥å®Œæ•´åŒ¹é… physical_node_id -> physical_nodes keys
                    # 2) è‹¥æœªå‘½ä¸­ï¼Œå°è¯•å¯¹ physical_nodes çš„ key åˆ—è¡¨è¿›è¡Œåç¼€åŒ¹é…ï¼ˆlast12, last8ï¼‰
                    # 3) è‹¥ä»æœªå‘½ä¸­ï¼Œåˆ™å°è¯•é€šè¿‡ ip/name æ˜ å°„ï¼ˆcontext ä¸­çš„ ip_address ä¸ physical_nodes ä¸­çš„ ip_address/nameï¼‰

                    physical_node_id = context.get("physical_node_id")
                    matched_physical_key = None

                    # ç›´æ¥ä½¿ç”¨å®Œæ•´ id
                    if physical_node_id and physical_node_id in physical_nodes:
                        matched_physical_key = physical_node_id
                    else:
                        # å°è¯•åç¼€åŒ¹é…
                        try:
                            if physical_node_id:
                                s = str(physical_node_id)
                                candidates = list(physical_nodes.keys())
                                # ä¼˜å…ˆå°è¯• longer suffix
                                for suf_len in (16, 12, 8):
                                    suf = s[-suf_len:]
                                    found = [k for k in candidates if str(k).endswith(suf)]
                                    if len(found) == 1:
                                        matched_physical_key = found[0]
                                        break
                                    elif len(found) > 1:
                                        # å¦‚æœæœ‰å¤šé‡åŒ¹é…ï¼Œå°½é‡é€šè¿‡ ip åœ°å€å†è¿‡æ»¤
                                        ip_addr = context.get('ip_address') or context.get('ip')
                                        if ip_addr:
                                            filtered = [k for k in found if physical_nodes.get(k, {}).get('ip_address') == ip_addr or physical_nodes.get(k, {}).get('node_name') == ip_addr]
                                            if len(filtered) == 1:
                                                matched_physical_key = filtered[0]
                                                break
                        except Exception:
                            matched_physical_key = None

                        # æœ€åå°è¯•é€šè¿‡ ip/name ç›´æ¥åŒ¹é…
                        if not matched_physical_key:
                            ip_addr = context.get('ip_address') or context.get('ip') or context.get('ip_address')
                            if ip_addr:
                                for k, v in physical_nodes.items():
                                    if v.get('ip_address') == ip_addr or v.get('node_name') == ip_addr or (isinstance(v.get('labels'), dict) and v.get('labels').get('node_ip') == ip_addr):
                                        matched_physical_key = k
                                        break

                    if matched_physical_key:
                        # å¦‚æœç‰©ç†èŠ‚ç‚¹å­˜åœ¨ï¼Œå°†CastRayä¿¡æ¯åˆå¹¶è¿›å»
                        if "castray_nodes" not in physical_nodes[matched_physical_key]:
                            physical_nodes[matched_physical_key]["castray_nodes"] = []
                        
                        # åˆå¹¶çŠ¶æ€ä¿¡æ¯ï¼Œå¹¶ä¿ç•™åŸå§‹ context
                        enhanced_status = {
                            **status,
                            "context": context,
                            "message_queue_size": len(status.get("received_messages", [])) + len(status.get("sent_messages", []))
                        }
                        physical_nodes[matched_physical_key]["castray_nodes"].append(enhanced_status)
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„ç‰©ç†èŠ‚ç‚¹ï¼Œè®°å½•ä¸ºç‹¬ç«‹çš„CastRayèŠ‚ç‚¹
                        logger.warning(f"CastRayèŠ‚ç‚¹ {node_id} æ— æ³•æ˜ å°„åˆ°ç‰©ç†èŠ‚ç‚¹ {physical_node_id}; å°è¯•é€šè¿‡ ip/name/calculation åŒ¹é…å¤±è´¥")
                        
                except Exception as e:
                    logger.error(f"å¤„ç†CastRayèŠ‚ç‚¹ {node_id} å¤±è´¥: {e}")
            
            # 4. æ·»åŠ å¤–éƒ¨èŠ‚ç‚¹ä¿¡æ¯
            for node_id, node_info in self.external_nodes.items():
                if node_info.get('is_ray_node'):
                    ray_node_id = node_info.get('ray_node_id')
                    if ray_node_id and ray_node_id in physical_nodes:
                        if "external_info" not in physical_nodes[ray_node_id]:
                            physical_nodes[ray_node_id]["external_info"] = []
                        physical_nodes[ray_node_id]["external_info"].append(node_info)
            
            # 5. ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰castray_nodeså­—æ®µ
            for node_id, node_data in physical_nodes.items():
                if "castray_nodes" not in node_data:
                    node_data["castray_nodes"] = []
                
                # è®¡ç®—èŠ‚ç‚¹çš„ç»¼åˆçŠ¶æ€
                node_data["has_castray_nodes"] = len(node_data["castray_nodes"]) > 0
                node_data["total_transfers"] = sum(
                    cn.get("file_transfer_stats", {}).get("successful_transfers", 0) 
                    for cn in node_data["castray_nodes"]
                )
                node_data["total_messages"] = sum(
                    cn.get("message_queue_size", 0) 
                    for cn in node_data["castray_nodes"]
                )

                # æ ‡å‡†åŒ–æ ‡è¯†å­—æ®µï¼šray_node_idï¼ˆå°½å¯èƒ½ä¸ºå®Œæ•´çš„ Ray NodeIDï¼‰ï¼Œshort_idï¼ˆæœ€å8ä½ï¼‰ï¼Œcanonical_idï¼ˆç”¨äºå‰ç«¯ç»Ÿä¸€é”®ï¼‰
                # 1) å¦‚æœå·²æœ‰ physical_node_id å­—æ®µä¸”çœ‹èµ·æ¥æ˜¯å®Œæ•´idï¼Œåˆ™ä½¿ç”¨
                ray_node_id = node_data.get('physical_node_id') or node_data.get('ray_node_id') or None
                # 2) å¦‚æœ key æœ¬èº«åƒä¸€ä¸ªå®Œæ•´ idï¼ˆåŒ…å« '-' æˆ–é•¿åº¦å¤§äº16ï¼‰ï¼Œå°è¯•ä½¿ç”¨å®ƒ
                if not ray_node_id:
                    if isinstance(node_id, str) and (len(node_id) > 16 or '-' in node_id or node_id.startswith('ray_node_')):
                        ray_node_id = node_id

                # 3) short_id ä¸ºæœ€å8ä½
                short_id = None
                if ray_node_id:
                    try:
                        short_id = str(ray_node_id)[-8:]
                    except Exception:
                        short_id = None

                # 4) canonical_id ä¼˜å…ˆä½¿ç”¨ ray_node_idï¼Œå¦åˆ™ä½¿ç”¨ node_idï¼ˆmap keyï¼‰
                canonical_id = ray_node_id or node_id

                node_data['ray_node_id'] = ray_node_id
                node_data['short_id'] = short_id
                node_data['canonical_id'] = canonical_id

                # è®°å½•è°ƒè¯•æ—¥å¿—ï¼Œå¸®åŠ©å®šä½å­—æ®µä¸ºä½•å¯èƒ½ä¸º None
                try:
                    logger.info(f"normalize-node: key={node_id} ray_node_id={ray_node_id} short_id={short_id} canonical_id={canonical_id}")
                except Exception:
                    pass
            
            # 6. è¿”å›èŠ‚ç‚¹åˆ—è¡¨
            unified_nodes = list(physical_nodes.values())
            logger.info(f"ç»Ÿä¸€èŠ‚ç‚¹çŠ¶æ€: {len(unified_nodes)} ä¸ªèŠ‚ç‚¹ï¼Œå…¶ä¸­ {sum(1 for n in unified_nodes if n['has_castray_nodes'])} ä¸ªæœ‰CastRayèŠ‚ç‚¹")
            
            return unified_nodes
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿä¸€èŠ‚ç‚¹çŠ¶æ€å¤±è´¥: {e}")
            return []
    
    async def get_node_messages(self, node_id: str, count: int = 50) -> list:
        """è·å–èŠ‚ç‚¹æ¶ˆæ¯"""
        try:
            if node_id in self.nodes:
                return await self.nodes[node_id].get_messages.remote(count)
            return []
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ {node_id} æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    async def initiate_node_file_transfer(self, sender_id: str, file_path: str, 
                                         recipients: List[str], transfer_mode: str = "unicast") -> CastResponse:
        """é€šè¿‡èŠ‚ç‚¹å‘èµ·æ–‡ä»¶ä¼ è¾“"""
        start_time = time.time()
        
        try:
            if sender_id not in self.nodes:
                return CastResponse(
                    success=False,
                    message="å‘é€èŠ‚ç‚¹ä¸å­˜åœ¨",
                    recipients_count=0
                )
            
            sender_node = self.nodes[sender_id]
            result = await sender_node.initiate_file_transfer.remote(
                file_path, recipients, transfer_mode
            )
            
            delivery_time = time.time() - start_time
            
            if result["success"]:
                return CastResponse(
                    success=True,
                    message=f"æ–‡ä»¶ä¼ è¾“å·²å‘èµ·: {result['file_id']}",
                    recipients_count=result["recipients_notified"],
                    delivery_time=delivery_time
                )
            else:
                return CastResponse(
                    success=False,
                    message=f"æ–‡ä»¶ä¼ è¾“å‘èµ·å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                    recipients_count=0,
                    delivery_time=delivery_time
                )
                
        except Exception as e:
            logger.error(f"å‘èµ·èŠ‚ç‚¹æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            return CastResponse(
                success=False,
                message=f"å‘èµ·å¤±è´¥: {str(e)}",
                recipients_count=0
            )
    
    async def schedule_auto_file_transfer(self, sender_id: str, file_path: str, 
                                        recipients: List[str], transfer_mode: str = "unicast",
                                        delay: float = 0) -> bool:
        """å®‰æ’è‡ªåŠ¨æ–‡ä»¶ä¼ è¾“"""
        try:
            if sender_id not in self.nodes:
                logger.error(f"å‘é€èŠ‚ç‚¹ä¸å­˜åœ¨: {sender_id}")
                return False
            
            sender_node = self.nodes[sender_id]
            await sender_node.schedule_auto_transfer.remote(
                file_path, recipients, transfer_mode, delay
            )
            
            logger.info(f"å·²å®‰æ’èŠ‚ç‚¹ {sender_id} çš„è‡ªåŠ¨æ–‡ä»¶ä¼ è¾“: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"å®‰æ’è‡ªåŠ¨æ–‡ä»¶ä¼ è¾“å¤±è´¥: {e}")
            return False
    
    async def get_file_transfer_status(self, node_id: Optional[str] = None) -> dict:
        """è·å–æ–‡ä»¶ä¼ è¾“çŠ¶æ€"""
        try:
            if node_id:
                # è·å–ç‰¹å®šèŠ‚ç‚¹çš„çŠ¶æ€
                if node_id in self.nodes:
                    status = await self.nodes[node_id].get_status.remote()
                    return {node_id: status}
                else:
                    return {"error": f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨"}
            else:
                # è·å–æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€
                all_status = {}
                for nid, node_ref in self.nodes.items():
                    try:
                        status = await node_ref.get_status.remote()
                        all_status[nid] = status
                    except Exception as e:
                        all_status[nid] = {"error": str(e)}
                
                return all_status
                
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶ä¼ è¾“çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def shutdown(self):
        """å…³é—­é›†ç¾¤"""
        try:
            for node_id in list(self.nodes.keys()):
                asyncio.create_task(self.remove_node(node_id))
            if ray.is_initialized():
                ray.shutdown()
            logger.info("é›†ç¾¤å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­é›†ç¾¤å¤±è´¥: {e}")


class NodeScheduler:
    """èŠ‚ç‚¹ä»»åŠ¡è°ƒåº¦å™¨ - ç”¨äºæ¼”ç¤ºè‡ªåŠ¨æ–‡ä»¶ä¼ è¾“"""
    
    def __init__(self, cluster: CastingCluster):
        self.cluster = cluster
        self.running = False
        self.demo_files_dir = Path("demo_files")
        self.demo_files_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ¼”ç¤ºæ–‡ä»¶
        self._create_demo_files()
    
    def _create_demo_files(self):
        """åˆ›å»ºæ¼”ç¤ºæ–‡ä»¶"""
        demo_files = [
            ("config.json", {"server": "localhost", "port": 8080, "timeout": 30}),
            ("data.txt", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\nåŒ…å«å¤šè¡Œæ•°æ®\nç”¨äºæ¼”ç¤ºæ–‡ä»¶ä¼ è¾“åŠŸèƒ½"),
            ("report.md", "# ç³»ç»ŸæŠ¥å‘Š\n\n## çŠ¶æ€\n- ç³»ç»Ÿè¿è¡Œæ­£å¸¸\n- æ‰€æœ‰èŠ‚ç‚¹åœ¨çº¿")
        ]
        
        for filename, content in demo_files:
            file_path = self.demo_files_dir / filename
            if not file_path.exists():
                if isinstance(content, dict):
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(content, f, ensure_ascii=False, indent=2)
                else:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                        
                logger.info(f"åˆ›å»ºæ¼”ç¤ºæ–‡ä»¶: {file_path}")
    
    async def start_demo_transfers(self):
        """å¯åŠ¨æ¼”ç¤ºä¼ è¾“"""
        self.running = True
        logger.info("å¼€å§‹æ¼”ç¤ºè‡ªåŠ¨æ–‡ä»¶ä¼ è¾“...")
        
        while self.running:
            try:
                # æ£€æŸ¥é›†ç¾¤çŠ¶æ€
                status = await self.cluster.get_cluster_status()
                active_nodes = [node['node_id'] for node in status.get('node_statuses', []) 
                              if node.get('is_running', False)]
                
                if len(active_nodes) >= 2:
                    # éšæœºé€‰æ‹©å‘é€è€…å’Œæ¥æ”¶è€…
                    import random
                    sender = random.choice(active_nodes)
                    receivers = [node for node in active_nodes if node != sender]
                    
                    if receivers:
                        # éšæœºé€‰æ‹©æ–‡ä»¶
                        demo_files = list(self.demo_files_dir.glob("*"))
                        if demo_files:
                            file_to_send = random.choice(demo_files)
                            selected_receivers = random.sample(receivers, min(2, len(receivers)))
                            
                            # å‘èµ·ä¼ è¾“
                            await self.cluster.schedule_auto_file_transfer(
                                sender, str(file_to_send), selected_receivers, "unicast", 0
                            )
                            
                            logger.info(f"æ¼”ç¤ºä¼ è¾“: {sender} -> {selected_receivers} æ–‡ä»¶: {file_to_send.name}")
                
                # ç­‰å¾…30ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡ä¼ è¾“
                await asyncio.sleep(30)
                
            except Exception as e:
                logger.error(f"æ¼”ç¤ºä¼ è¾“é”™è¯¯: {e}")
                await asyncio.sleep(10)
    
    def stop_demo_transfers(self):
        """åœæ­¢æ¼”ç¤ºä¼ è¾“"""
        self.running = False
        logger.info("åœæ­¢æ¼”ç¤ºä¼ è¾“")


# ç‰©ç†èŠ‚ç‚¹çŠ¶æ€è·å–å‡½æ•°
def get_physical_ray_nodes_status(dashboard_address: str) -> dict:
    """
    ä»Ray Dashboard APIè·å–ç‰©ç†èŠ‚ç‚¹çš„çŠ¶æ€ã€‚
    è¿™æ˜¯ä»rayoutput.pyæ•´åˆè¿‡æ¥çš„åŠŸèƒ½ã€‚
    """
    import requests
    import json
    
    nodes_info = {}
    try:
        # å°è¯•è¿æ¥åˆ°Ray Dashboardçš„API
        response = requests.get(f"http://{dashboard_address}/api/v0/nodes?view=summary", timeout=5)
        response.raise_for_status()
        data = response.json()

        # Ray Dashboard çš„ JSON ç»“æ„åœ¨ä¸åŒç‰ˆæœ¬ä¸­å·®å¼‚è¾ƒå¤§ï¼Œå¸¸è§å½¢å¼æœ‰ï¼š
        # - {"data": {"summary": [...]}}
        # - {"result": [...]} æˆ– {"data": {"result": {"result": [...]}}}
        # ä¸ºäº†é²æ£’æ€§ï¼Œè¿™é‡Œé€’å½’å¯»æ‰¾ç¬¬ä¸€ä¸ªçœ‹èµ·æ¥åƒèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå…ƒç´ ä¸º dict ä¸”åŒ…å« node_id/NodeID/nodeIdï¼‰çš„åˆ—è¡¨ã€‚
        def find_nodes_list(obj, depth=0):
            if depth > 6:
                return None
            if isinstance(obj, list):
                if obj and all(isinstance(i, dict) for i in obj):
                    # åˆ¤æ–­åˆ—è¡¨å†…å…ƒç´ æ˜¯å¦æ˜¯èŠ‚ç‚¹ dictï¼ˆåŒ…å« node_id/NodeID/nodeId ç­‰å­—æ®µï¼‰
                    for item in obj:
                        if any(k in item for k in ("node_id", "NodeID", "nodeId")):
                            return obj
                return None
            if isinstance(obj, dict):
                # ä¼˜å…ˆæ£€æŸ¥å¸¸è§é”®
                for key in ("data", "result", "nodes", "summary"):
                    if key in obj:
                        candidate = obj[key]
                        found = find_nodes_list(candidate, depth + 1)
                        if found:
                            return found
                # é€’å½’éå†å­—å…¸çš„å€¼
                for v in obj.values():
                    found = find_nodes_list(v, depth + 1)
                    if found:
                        return found
            return None

        summaries = find_nodes_list(data) or []

        if not summaries:
            logger.error("ä»Ray Dashboardè·å–ç‰©ç†èŠ‚ç‚¹çŠ¶æ€å¤±è´¥: æœªèƒ½æ‰¾åˆ°èŠ‚ç‚¹æ•°ç»„ (unknown structure)")
            return nodes_info

        for node_data in summaries:
            # å®‰å…¨æå– node idï¼Œå…¼å®¹å¤šç§å­—æ®µå‘½å
            node_id = None
            ip_addr = None
            state = "unknown"
            resources = {}
            labels = {}
            is_head = False

            if isinstance(node_data, dict):
                # å¸¸è§åµŒå¥—ç»“æ„
                raylet = node_data.get("raylet") or node_data.get("meta") or {}
                if isinstance(raylet, dict):
                    node_id = raylet.get("nodeId") or raylet.get("NodeID") or raylet.get("node_id")
                    state = raylet.get("state", state)
                    is_head = raylet.get("isHeadNode", is_head) or raylet.get("is_head", is_head)

                # ç›´æ¥å­—æ®µçš„å¤‡é€‰
                node_id = node_id or node_data.get("node_id") or node_data.get("NodeID") or node_data.get("nodeId") or node_data.get("raylet_node_id")
                ip_addr = node_data.get("ip") or node_data.get("node_ip") or node_data.get("ip_address")
                resources = node_data.get("resources") or node_data.get("ResourceUsage") or node_data.get("resources_total") or {}
                labels = node_data.get("labels") or node_data.get("meta", {})

            if not node_id:
                # å¦‚æœä»æœªèƒ½æ‰¾åˆ° node idï¼Œè·³è¿‡è¯¥æ¡ç›®
                continue

            nodes_info[node_id] = {
                "physical_node_id": node_id,
                "ip_address": ip_addr,
                "status": state,
                "cpu_usage": node_data.get("cpu", 0) if isinstance(node_data, dict) else 0,
                "mem_usage": node_data.get("mem", [0, 1]) if isinstance(node_data, dict) else [0, 1],
                "gpu_usage": node_data.get("gpus", []) if isinstance(node_data, dict) else [],
                "disk_usage": node_data.get("disk", {}) if isinstance(node_data, dict) else {},
                "labels": labels,
                "is_head": is_head,
                "node_name": labels.get("node_name", ip_addr or "unknown") if isinstance(labels, dict) else (ip_addr or "unknown"),
                "resources": resources or {},
                "timestamp": time.time()
            }
    except Exception as e:
        logger.error(f"ä»Ray Dashboardè·å–ç‰©ç†èŠ‚ç‚¹çŠ¶æ€å¤±è´¥: {e}")
    return nodes_info


async def manual_transfer_demo(sender_id: str, file_name: str, recipients: List[str]):
    """æ‰‹åŠ¨è§¦å‘æ¼”ç¤ºä¼ è¾“ï¼ˆé¡¶çº§è¾…åŠ©å‡½æ•°ï¼‰

    This helper calls the global `cluster` to initiate a transfer. It is async
    and intended for use by external callers or debugging. It is implemented at
    module level (not bound to NodeScheduler) so it can be awaited when useful.
    """
    demo_files_dir = Path("demo_files")
    file_path = demo_files_dir / file_name
    if file_path.exists():
        result = await cluster.initiate_node_file_transfer(sender_id, str(file_path), recipients, "unicast")
        return result
    else:
        return CastResponse(
            success=False,
            message=f"æ¼”ç¤ºæ–‡ä»¶ä¸å­˜åœ¨: {file_name}",
            recipients_count=0
        )


# å…¨å±€é›†ç¾¤å®ä¾‹
cluster = CastingCluster()

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = NodeScheduler(cluster)

